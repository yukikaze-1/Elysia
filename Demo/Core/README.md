# Core 核心基础设施

`Core` 模块是 Elysia 系统的核心基础设施层，提供了系统的骨架，负责组件间的通信、任务调度、数据定义以及基础服务。它不包含具体的业务逻辑（如具体的感知算法或人格模型），而是连接各个功能层（Layers）的纽带。

## 模块概览

| 文件 | 模块名 | 描述 |
| --- | --- | --- |
| `Dispatcher.py` | **调度器** | 系统的中央控制器，协调感知、认知、记忆和表达各层的工作流程。 |
| `EventBus.py` | **事件总线** | 基于发布-订阅模式的消息通信中枢，实现组件间的解耦。 |
| `ActuatorLayer.py` | **执行层** | 负责将 AI 的决策转化为外部行动（如语音、指令），管理输出通道。 |
| `SystemClock.py` | **系统时钟** | 提供系统心跳（Tick），驱动周期性任务和时间相关的逻辑。 |
| `Schema.py` | **数据模式** | 定义系统通用的数据结构、事件类型和枚举。 |
| `OutputChannel.py` | **输出通道** | 定义输出接口标准，并提供基础实现（如控制台输出）。 |

## 详细说明

### 1. Dispatcher (调度器)
`Dispatcher` 是整个系统的大脑。它负责：
- **事件分发**：从 `EventBus` 接收事件，并根据事件类型调用 L0-L3 各层的处理逻辑。
- **流程协调**：管理数据在感知层 (L0)、大脑层 (L1)、记忆层 (L2) 和人格层 (L3) 之间的流动。
- **主动性管理**：实现 Agency 逻辑，决定 AI 何时主动发起交互。

### 2. EventBus (事件总线)
`EventBus` 实现了观察者模式，是系统内部通信的高速公路。
- **线程安全**：使用 `queue.Queue` 处理多线程环境下的事件传递。
- **发布/订阅**：组件可以订阅特定类型的事件（如 `SYSTEM_TICK`），也可以发布事件（如 `USER_INPUT`）。

### 3. ActuatorLayer (执行层)
`ActuatorLayer` 是 AI 对外行动的接口。
- **动作执行**：处理 `SPEECH` (说话) 和 `COMMAND` (指令) 等动作。
- **多通道支持**：可以注册多个 `OutputChannel`（如终端、WebSocket 客户端、TTS 引擎），将内容分发到不同的端点。

### 4. SystemClock (系统时钟)
`SystemClock` 是系统的心脏。
- **心跳机制**：在独立线程中运行，定期发送 `SYSTEM_TICK` 事件。
- **时间驱动**：驱动心理系统 (PsycheSystem) 的状态衰减、环境感知更新等周期性任务。

### 5. Schema (数据模式)
`Schema` 定义了系统的“通用语言”。
- **Event**：标准事件对象，包含类型、来源、内容和时间戳。
- **Enums**：定义了 `EventType` (事件类型)、`EventSource` (来源) 等枚举值，规范系统常量。

### 6. OutputChannel (输出通道)
`OutputChannel` 定义了输出的抽象基类。
- **扩展性**：开发者可以通过继承 `OutputChannel` 来实现不同的输出方式（例如接入 Live2D 前端或 Discord 机器人）。
- **ConsoleChannel**：提供了一个默认的控制台输出实现，支持带颜色的日志打印。

## 交互流程示例

一个典型的交互流程如下：

1.  **输入**: 外部输入（如用户消息）被封装为 `Event`，通过 `EventBus` 发布。
2.  **调度**: `Dispatcher` 监听到事件，调用 `L0` 感知层进行处理。
3.  **认知**: `Dispatcher` 将感知结果传递给 `L1` 大脑层和 `L2` 记忆层生成响应。
4.  **决策**: `L3` 人格层对响应进行润色。
5.  **执行**: `Dispatcher` 调用 `ActuatorLayer` 执行最终决策。
6.  **输出**: `ActuatorLayer` 通过注册的 `OutputChannel` 将回复发送给用户。
