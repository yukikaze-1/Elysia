import streamlit as st
import requests
import time
import pandas as pd
from datetime import datetime

# === é…ç½® ===
API_URL = "http://192.168.1.18:8000"
REFRESH_RATE = 1.0  # åˆ·æ–°é¢‘ç‡(ç§’)

st.set_page_config(
    page_title="Elysia Monitor",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# === CSS ç¾åŒ– ===
st.markdown("""
<style>
    /* å…¨å±€å­—ä½“ä¼˜åŒ– */
    .block-container { padding-top: 1rem; padding-bottom: 1rem; }
    
    /* å¡ç‰‡æ ·å¼ */
    .metric-card {
        background-color: #f8f9fa;
        border: 1px solid #e9ecef;
        padding: 15px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        margin-bottom: 10px;
    }
    
    /* çŠ¶æ€æŒ‡ç¤ºç¯ */
    .status-indicator {
        display: inline-block;
        width: 10px;
        height: 10px;
        border-radius: 50%;
        margin-right: 5px;
    }
    .status-on { background-color: #28a745; box-shadow: 0 0 5px #28a745; }
    .status-off { background-color: #dc3545; }
    
    /* æ€ç»´é“¾æ°”æ³¡ */
    .thought-bubble {
        background-color: #e3f2fd;
        border-left: 4px solid #2196f3;
        padding: 10px 15px;
        border-radius: 0 10px 10px 0;
        margin-bottom: 10px;
        font-style: italic;
        color: #0d47a1;
    }
    .reply-bubble {
        background-color: #ffffff;
        border: 1px solid #ddd;
        padding: 10px 15px;
        border-radius: 10px;
        color: #333;
    }
    
    /* è¿›åº¦æ¡å®¹å™¨ä¼˜åŒ– */
    .stProgress > div > div > div > div {
        background-image: linear-gradient(to right, #4caf50, #8bc34a);
    }
    
    /* ç»™ä¸åŒçŠ¶æ€å®šä¹‰é¢œè‰²ç±» (éœ€é…åˆ st.markdown ä½¿ç”¨ html æ¸²æŸ“ï¼Œä½† Streamlit åŸç”Ÿ progress é¢œè‰²å—é™ï¼Œ
       è¿™é‡Œä¸»è¦ä¼˜åŒ–æ–‡å­—æ˜¾ç¤º) */
    .stat-label { font-size: 0.8rem; color: #666; margin-bottom: -5px; }
    .stat-value { font-size: 1.5rem; font-weight: bold; }
    .warning { color: #ff9800; }
    .danger { color: #dc3545; }
    .success { color: #28a745; }
    
    /* è®°å¿†æ—¥å¿—è¡¨æ ¼ä¼˜åŒ– */
    .dataframe { font-size: 0.8rem !important; }
</style>
""", unsafe_allow_html=True)

def fetch_state():
    """ä» FastAPI è·å–å…¨é‡çŠ¶æ€"""
    try:
        resp = requests.get(f"{API_URL}/dashboard/snapshot", timeout=0.5)
        if resp.status_code == 200:
            return resp.json()
    except Exception:
        return None
    return None

def format_timestamp(ts):
    """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
    if isinstance(ts, (int, float)) and ts > 0:
        return datetime.fromtimestamp(int(ts)).strftime("%H:%M:%S")
    return "Never"

# === ä¸»ç•Œé¢ ===
st.title("ğŸ§  Elysia Neural Dashboard")

# å ä½å®¹å™¨ï¼Œç”¨äºè‡ªåŠ¨åˆ·æ–°
main_container = st.empty()

while True:
    state = fetch_state()
    
    with main_container.container():
        if not state:
            st.error("âš ï¸ Connection Lost. Waiting for Elysia Server...")
            time.sleep(2)
            continue

        # è·å–å„å±‚æ•°æ®
        sys = state.get("system", {})
        l3 = state.get("l3_persona", {})
        l0 = state.get("l0_sensor", {})
        actuator = state.get("actuator", {})
        psyche = state.get("psyche", {})     # <--- è·å–æ–°å¢çš„ Psyche æ•°æ®
        psyche_cfg = psyche.get("config", {}) # è·å–é…ç½®

        # ==========================================
        # 1. é¡¶æ ï¼šç³»ç»Ÿå¥åº·åº¦ & L3 äººè®¾çŠ¶æ€
        # ==========================================
        dispatcher_status = "status-on" if sys.get("dispatcher_alive") else "status-off"
        
        # å®šä¹‰ 5 åˆ—å¸ƒå±€
        cols = st.columns([1, 1, 1, 1, 2])
        
        with cols[0]:
            st.markdown(f'<div class="metric-card"><b>Dispatcher</b><br><span class="status-indicator {dispatcher_status}"></span>{"Alive" if sys.get("dispatcher_alive") else "Dead"}</div>', unsafe_allow_html=True)
            
        with cols[1]:
            st.markdown(f'<div class="metric-card"><b>Online Clients</b><br>ğŸ”Œ {sys.get("online_clients", 0)}</div>', unsafe_allow_html=True)
            
        with cols[2]:
            st.markdown(f'<div class="metric-card"><b>Input Queue</b><br>ğŸ“¥ {l0.get("input_queue_size", 0)}</div>', unsafe_allow_html=True)

        with cols[3]:
            # === [å±•ç¤º 1] L3 Mood (äººè®¾è¡¨ç°å‡ºçš„å¿ƒæƒ… - String) ===
            l3_mood = l3.get("mood", "Neutral")
            mood_color = "orange" if l3_mood in ["Sad", "Angry"] else "green"
            st.markdown(f'<div class="metric-card"><b>L3 Persona Mood</b><br><span style="color:{mood_color}; font-weight:bold">{l3_mood}</span></div>', unsafe_allow_html=True)

        with cols[4]:
            channels = actuator.get("registered_channels", [])
            st.markdown(f'<div class="metric-card"><b>Actuator Channels</b><br>ğŸ“¢ {", ".join(channels)}</div>', unsafe_allow_html=True)

        st.divider()

        # ==========================================
        # 2. [æ–°å¢] ç”Ÿç†ä¸å¿ƒç†ç›‘æ§ (Psyche System)
        #    è¿™é‡Œæ’å…¥ä½ çš„æ–°æ¨¡å—ï¼Œä½äº Top Bar å’Œ Tabs ä¹‹é—´
        # ==========================================
        st.subheader("ğŸ§¬ Physiological & Internal State")
        
        # å¸ƒå±€ï¼š4 åˆ— (ç²¾åŠ› | ç¤¾äº¤ | æ— èŠ | å†…åœ¨å¿ƒæƒ…)
        p1, p2, p3, p4 = st.columns(4)
        
        # --- A. Energy (ç²¾åŠ›) ---
        with p1:
            energy = float(psyche.get("energy", 100))
            max_energy = float(psyche_cfg.get("max_energy", 100))
            energy_pct = max(0.0, min(1.0, energy / max_energy)) if max_energy > 0 else 0
            
            e_icon = "ğŸ”‹" if energy > 50 else "ğŸª«"
            if energy < 20: e_icon = "ğŸ’¤"
            
            st.markdown(f"<div class='stat-label'>Physical Energy {e_icon}</div>", unsafe_allow_html=True)
            st.markdown(f"<div class='stat-value'>{energy:.1f}</div>", unsafe_allow_html=True)
            st.progress(energy_pct)
            
            # æ˜¾ç¤ºæ¢å¤/æ¶ˆè€—é€Ÿç‡
            drain = psyche_cfg.get("energy_drain_rate", 0)
            recover = psyche_cfg.get("energy_recover_rate", 0)
            st.caption(f"Drain: -{drain}/h | Sleep: +{recover}/h")

        # --- B. Social Battery (ç¤¾äº¤ç”µé‡) ---
        with p2:
            social = float(psyche.get("social_battery", 100))
            max_social = float(psyche_cfg.get("max_social_battery", 100))
            social_pct = max(0.0, min(1.0, social / max_social)) if max_social > 0 else 0
            
            s_icon = "ğŸ’¬" if social > 30 else "ğŸ˜¶"
            
            st.markdown(f"<div class='stat-label'>Social Battery {s_icon}</div>", unsafe_allow_html=True)
            st.markdown(f"<div class='stat-value'>{social:.1f}</div>", unsafe_allow_html=True)
            st.progress(social_pct)
            
            st.caption(f"Cost (Passive): -{psyche_cfg.get('cost_speak_passive', 0)}/msg")

        # --- C. Boredom (è¡¨è¾¾æ¬²) ---
        with p3:
            boredom = float(psyche.get("boredom", 0))
            threshold = float(psyche_cfg.get("boredom_threshold", 80))
            
            # è®¡ç®—æ— èŠè¿›åº¦
            boredom_pct = max(0.0, min(1.0, boredom / threshold)) if threshold > 0 else 0
            
            b_icon = "ğŸ¥±"
            b_val_color = "inherit"
            if boredom >= threshold:
                b_icon = "ğŸ“¢" # è§¦å‘é˜ˆå€¼
                b_val_color = "#dc3545" # å˜çº¢
            
            st.markdown(f"<div class='stat-label'>Boredom / Drive {b_icon}</div>", unsafe_allow_html=True)
            st.markdown(f"<div class='stat-value' style='color:{b_val_color}'>{boredom:.1f} <span style='font-size:1rem;color:#999'>/ {threshold}</span></div>", unsafe_allow_html=True)
            st.progress(boredom_pct)
            
            growth = psyche_cfg.get("base_boredom_growth", 0)
            st.caption(f"Growth: +{growth}/h")

        # --- D. [å±•ç¤º 2] Psyche Mood (å†…åœ¨åŸºè°ƒ - Numeric/String) ---
        with p4:
            # è·å– Psyche Mood
            psyche_mood = psyche.get("mood", "Stable") 
            
            # æ¸²æŸ“ä¸€ä¸ªå¡ç‰‡æˆ–è€…å¤§å­—æ˜¾ç¤º
            st.markdown(f"<div class='stat-label'>Internal Psyche Mood ğŸ§ </div>", unsafe_allow_html=True)
            st.markdown(f"<div class='stat-value' style='color:#4e8cff'>{psyche_mood}</div>", unsafe_allow_html=True)
            st.caption("Base emotional substrate")

        # --- E. é…ç½®è¯¦æƒ… (æŠ˜å ) ---
        with st.expander("ğŸ§¬ View Psyche DNA Configuration", expanded=False):
            if psyche_cfg:
                c_df = pd.DataFrame([{"Parameter": k, "Value": v} for k, v in psyche_cfg.items()])
                st.dataframe(c_df, width='stretch', hide_index=True)
            else:
                st.info("No configuration data received.")
        # ==========================================
        # 2. æ ¸å¿ƒåŠŸèƒ½åŒº (Tabs)
        # ==========================================
        tab_brain, tab_memory, tab_reflector, tab_raw = st.tabs(["ğŸ§  Brain & Thought", "ğŸ’¾ Memory & Session", "ğŸª Reflector Logs", "ğŸ“ Raw Data"])
        
        # --- Tab 1: Brain (L1) ---
        with tab_brain:
            l1 = state.get("l1_brain", {})
            col_b1, col_b2 = st.columns([1, 2])
            
            with col_b1:
                st.info("Configuration")
                st.text(f"Model: {l1.get('model_name')}")
                st.text(f"Temp:  {l1.get('temperature')}")
                
                # æ˜¾ç¤º System Prompt (æŠ˜å )
                with st.expander("Show L3 System Prompt"):
                    st.code(l3.get("prompt", ""), language="text")

            with col_b2:
                st.subheader("Last Thinking Process")
                log = l1.get("last_thinking_log")
                
                if log:
                    # åŒºåˆ†ä¸»åŠ¨å›å¤ (Active) å’Œ è¢«åŠ¨å›å¤ (Normal)
                    is_active = "should_speak" in log
                    
                    if is_active:
                        st.caption(f"Type: Active Decision | Should Speak: {log.get('should_speak')}")
                        inner = log.get("inner_voice", "")
                    else:
                        st.caption("Type: Response Generation")
                        inner = log.get("inner_thought", "")
                    
                    # æ¸²æŸ“æ€ç»´æ°”æ³¡
                    if inner:
                        st.markdown(f"""
                        <div class="thought-bubble">
                            <b>ğŸ’­ Inner Thought:</b><br>{inner}
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # æ¸²æŸ“å›å¤æ°”æ³¡
                    reply = log.get("public_reply")
                    if reply:
                        st.markdown(f"""
                        <div class="reply-bubble">
                            <b>ğŸ—£ï¸ Elysia:</b> {reply}
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown("*No public reply generated.*")
                else:
                    st.warning("No thoughts recorded yet.")

        # --- Tab 2: Memory & Session (å·²é€‚é…æ¶æ„é‡æ„) ---
        with tab_memory:
            # === å˜æ›´ç‚¹ï¼šåˆ†åˆ«è·å–ç‹¬ç«‹çš„ Session å’Œ L2 Memory æ•°æ® ===
            sess = state.get("session", {})      # ç°åœ¨ Session æ˜¯é¡¶çº§å¯¹è±¡
            l2 = state.get("l2_memory", {})      # L2 Memory åªè´Ÿè´£å‘é‡åº“ä¿¡æ¯
            
            # 1. ä¼šè¯çŠ¶æ€æŒ‡æ ‡ (Session Metrics)
            m1, m2, m3, m4 = st.columns(4)
            
            # è·å–åŸºç¡€ä¿¡æ¯
            role = sess.get("role", "AI")
            user = sess.get("user_name", "User")
            m1.metric("Session Role", role)
            m2.metric("User Name", user)
            
            # Context Window è¿›åº¦æ¡
            curr_msg = sess.get("total_messages", 0)
            max_msg = sess.get("max_messages_limit", 20)
            # é˜²æ­¢é™¤é›¶é”™è¯¯
            progress = 0.0
            if max_msg > 0:
                progress = min(curr_msg / max_msg, 1.0)
            
            m3.metric("Context Window", f"{curr_msg} / {max_msg}")
            m3.progress(progress)
            
            # æ—¶é—´æˆ³
            last_ts = sess.get("last_interaction_time", 0)
            # ç®€å•çš„æ ¼å¼åŒ–å‡½æ•°ï¼Œå¦‚æœä¹‹å‰æœªå®šä¹‰ï¼Œå¯ä»¥ä½¿ç”¨ datetime.fromtimestamp
            ts_str = "Never"
            if last_ts > 0:
                ts_str = datetime.fromtimestamp(last_ts).strftime("%H:%M:%S")
            m4.metric("Last Interaction", ts_str)
            
            st.divider()
            
            # 2. èŠå¤©è®°å½•å¯è§†åŒ– (Chat History)
            st.subheader("ğŸ’¬ Active Context (Session Buffer)")
            
            # è·å–æœ€è¿‘çš„æ¶ˆæ¯åˆ—è¡¨
            # æ³¨æ„ï¼šç¡®ä¿ä½ çš„ SessionState.get_status è¿”å›äº† "last_few_messages"
            recent_msgs = sess.get("last_few_messages", [])
            
            if recent_msgs:
                chat_container = st.container(height=400) # å›ºå®šé«˜åº¦æ»šåŠ¨å®¹å™¨
                with chat_container:
                    for msg in recent_msgs:
                        role_tag = msg.get("role", "user")
                        content = msg.get("content", "")
                        
                        # è®¾ç½®å¤´åƒ
                        avatar = "ğŸ‘¤" if role_tag == "user" else "ğŸ¤–"
                        
                        # æ¸²æŸ“æ°”æ³¡
                        with st.chat_message(name=role_tag, avatar=avatar):
                            st.markdown(content)
                            # å¦‚æœæœ‰æ—¶é—´æˆ³ä¹Ÿå¯ä»¥æ˜¾ç¤º
                            # st.caption(format_timestamp(msg.get("client_timestamp")))
            else:
                st.info("No active conversation in RAM.")

            st.divider()
            
            # 3. å‘é‡æ•°æ®åº“ä¿¡æ¯ (L2 Vector DB)
            # è¿™éƒ¨åˆ†ä¿¡æ¯ä¾ç„¶ä¿ç•™åœ¨ l2_memory ä¸­
            st.subheader("ğŸ“š Long-term Memory (Vector DB)")
            c1, c2 = st.columns(2)
            with c1:
                st.markdown(f"**Micro Collection:** `{l2.get('micro_memory_collection', 'N/A')}`")
            with c2:
                st.markdown(f"**Macro Collection:** `{l2.get('macro_memory_collection', 'N/A')}`")
            
        # --- Tab 3: Reflector ---
        with tab_reflector:
            ref = state.get("reflector", {})
            
            # ==================================================
            # 1. æš´åŠ›å¯»è·¯ (Robust Data Finder)
            # ==================================================
            # å®šä¹‰ä¸€ä¸ªå†…éƒ¨å‡½æ•°ï¼Œä¸“é—¨ç”¨æ¥åœ¨å­—å…¸é‡Œæ‰¾ "last_macro_reflection_log"
            def find_key_in_dict(source_dict, target_key):
                # A. ç›´æ¥åœ¨å½“å‰å±‚æ‰¾
                if target_key in source_dict:
                    return source_dict[target_key]
                # B. åœ¨å­å­—å…¸é‡Œæ‰¾ (æ¯”å¦‚ macro_reflector_status)
                for key, value in source_dict.items():
                    if isinstance(value, dict) and target_key in value:
                        return value[target_key]
                return None

            # æŸ¥æ‰¾ Macro æ•°æ®
            macro_logs = find_key_in_dict(ref, "last_macro_reflection_log") or []
            macro_time = find_key_in_dict(ref, "last_macro_reflection_time") or "Never"
            
            # æŸ¥æ‰¾ Micro æ•°æ®
            micro_logs = find_key_in_dict(ref, "last_micro_reflection_log") or []
            micro_time = find_key_in_dict(ref, "last_micro_reflection_time") or "Never"
            
            # ç¼“å†²æ± å¤§å° (é€šå¸¸ç›´æ¥åœ¨ ref å±‚)
            buffer_size = ref.get("buffer_size", 0)

            # ==================================================
            # 2. æ¸²æŸ“ç•Œé¢
            # ==================================================
            
            # æ¦‚è§ˆæŒ‡æ ‡
            r1, r2, r3 = st.columns(3)
            r1.metric("Buffer Size", buffer_size)
            r2.metric("Last Micro Run", str(micro_time))
            r3.metric("Last Macro Run", str(macro_time))
            
            st.divider()
            
            col_micro, col_macro = st.columns([1, 1.3])
            
            # --- Micro Logs ---
            with col_micro:
                st.subheader(f"Micro-Reflections ({len(micro_logs)})")
                if micro_logs and isinstance(micro_logs, list):
                    # æ•°æ®æ¸…æ´—ï¼šè½¬å­—ç¬¦ä¸²é˜²æ­¢æ¸²æŸ“é”™è¯¯
                    clean_micro = [{k: str(v) for k, v in item.items()} for item in micro_logs]
                    st.dataframe(clean_micro, width='stretch', hide_index=True)
                else:
                    st.info("No micro-memories yet.")

            # --- Macro Logs (ä¿®å¤é‡ç‚¹) ---
            with col_macro:
                st.subheader(f"Macro-Reflections ({len(macro_logs)})")
                
                if macro_logs and isinstance(macro_logs, list):
                    for i, log in enumerate(macro_logs):
                        # æå–æ•°æ®
                        ts = log.get("timestamp", 0)
                        # å¦‚æœ timestamp æ˜¯ float/intï¼Œå°è¯•æ ¼å¼åŒ–ï¼Œå¦åˆ™ç›´æ¥æ˜¾ç¤º
                        if isinstance(ts, (int, float)):
                            time_str = datetime.fromtimestamp(ts).strftime("%H:%M:%S")
                        else:
                            time_str = str(ts)
                            
                        emotion = log.get("dominant_emotion", "Unknown")
                        poignancy = log.get("poignancy", "?")
                        subject = log.get("subject", "General")
                        
                        label = f"ğŸ“… {time_str} | {subject} - {emotion} (Intensity: {poignancy})"
                        
                        with st.expander(label, expanded=(i==0)):
                            # æ ‡ç­¾æ¸²æŸ“
                            tags = log.get("keywords", [])
                            if isinstance(tags, list):
                                st.markdown(" ".join([f"`#{t}`" for t in tags]))
                            
                            st.divider()
                            
                            # å†…å®¹æ¸²æŸ“
                            content = log.get("diary_content", "No content")
                            st.caption("Diary Content:")
                            st.markdown(f"> {content}")
                            
                            # åŸå§‹æ•°æ®è°ƒè¯• (å¯é€‰)
                            # st.json(log)
                else:
                    st.info("No macro-memories yet.")
                    
                    # === ç»ˆæè°ƒè¯•é¢æ¿ ===
                    # å¦‚æœè¿˜æ˜¯æ˜¾ç¤ºä¸å‡ºæ¥ï¼Œå±•å¼€è¿™ä¸ªçœ‹çœ‹åˆ°åº• ref é•¿ä»€ä¹ˆæ ·
                    with st.expander("ğŸ•µï¸ Debug: Inspect Raw Reflector State", expanded=False):
                        st.write("Streamlit sees this data structure for 'reflector':")
                        st.json(ref)

        # --- Tab 4: Raw Data ---
        with tab_raw:
            st.json(state)

    time.sleep(REFRESH_RATE)